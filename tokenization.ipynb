{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNrZA8hPqWthDb5aZJMvgP+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WZYkzT0CwuyA","executionInfo":{"status":"ok","timestamp":1715105053024,"user_tz":-330,"elapsed":2470,"user":{"displayName":"Aakanksha Patil","userId":"12153990072553635480"}},"outputId":"25aba530-3fc1-484b-ec57-ffd346658ca1"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","from nltk.tokenize import sent_tokenize\n","from nltk.tokenize import wordpunct_tokenize\n","from nltk.tokenize import TreebankWordTokenizer\n","from nltk.tokenize import (word_tokenize , MWETokenizer)\n","from nltk.tokenize import TweetTokenizer"]},{"cell_type":"code","source":["text = \"Hey there! 😀 Just wanted to say hi! 🙌 Hope you're doing well. 🌞 Let's catch up soon! 🍕🥤\""],"metadata":{"id":"uRnPdiZaOh9F","executionInfo":{"status":"ok","timestamp":1715105133586,"user_tz":-330,"elapsed":363,"user":{"displayName":"Aakanksha Patil","userId":"12153990072553635480"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["print(word_tokenize(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kIsMOTtNO3N8","executionInfo":{"status":"ok","timestamp":1715105137569,"user_tz":-330,"elapsed":8,"user":{"displayName":"Aakanksha Patil","userId":"12153990072553635480"}},"outputId":"3d7371ea-79d5-44c2-a392-ff932307e10d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['Hey', 'there', '!', '😀', 'Just', 'wanted', 'to', 'say', 'hi', '!', '🙌', 'Hope', 'you', \"'re\", 'doing', 'well', '.', '🌞', 'Let', \"'s\", 'catch', 'up', 'soon', '!', '🍕🥤']\n"]}]},{"cell_type":"code","source":["print(sent_tokenize(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cMJYNEd-O3zt","executionInfo":{"status":"ok","timestamp":1715105157734,"user_tz":-330,"elapsed":419,"user":{"displayName":"Aakanksha Patil","userId":"12153990072553635480"}},"outputId":"35666bc6-a8bb-4746-ec22-f52cf4541c0a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["['Hey there!', '😀 Just wanted to say hi!', \"🙌 Hope you're doing well.\", \"🌞 Let's catch up soon!\", '🍕🥤']\n"]}]},{"cell_type":"code","source":["print(wordpunct_tokenize(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AiGnwfC8O8zM","executionInfo":{"status":"ok","timestamp":1715105170268,"user_tz":-330,"elapsed":8,"user":{"displayName":"Aakanksha Patil","userId":"12153990072553635480"}},"outputId":"f71888f0-5ad8-4c5c-e9e1-abcaf3145785"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["['Hey', 'there', '!', '😀', 'Just', 'wanted', 'to', 'say', 'hi', '!', '🙌', 'Hope', 'you', \"'\", 're', 'doing', 'well', '.', '🌞', 'Let', \"'\", 's', 'catch', 'up', 'soon', '!', '🍕🥤']\n"]}]},{"cell_type":"code","source":["tokenizer =TreebankWordTokenizer()\n","print(tokenizer.tokenize(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-4Jtj2H6O_8v","executionInfo":{"status":"ok","timestamp":1715105227053,"user_tz":-330,"elapsed":374,"user":{"displayName":"Aakanksha Patil","userId":"12153990072553635480"}},"outputId":"06df7a87-c43a-4a3d-c261-9ce1f9cf187e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["['Hey', 'there', '!', '😀', 'Just', 'wanted', 'to', 'say', 'hi', '!', '🙌', 'Hope', 'you', \"'re\", 'doing', 'well.', '🌞', 'Let', \"'s\", 'catch', 'up', 'soon', '!', '🍕🥤']\n"]}]},{"cell_type":"code","source":["tokenizer = MWETokenizer()\n","print(tokenizer.tokenize(word_tokenize(text)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9omhfS6FPNyT","executionInfo":{"status":"ok","timestamp":1715105239956,"user_tz":-330,"elapsed":380,"user":{"displayName":"Aakanksha Patil","userId":"12153990072553635480"}},"outputId":"fdfe8556-3470-4049-b204-5528eaa57916"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["['Hey', 'there', '!', '😀', 'Just', 'wanted', 'to', 'say', 'hi', '!', '🙌', 'Hope', 'you', \"'re\", 'doing', 'well', '.', '🌞', 'Let', \"'s\", 'catch', 'up', 'soon', '!', '🍕🥤']\n"]}]},{"cell_type":"code","source":["tokenizer =TweetTokenizer()\n","print(tokenizer.tokenize(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"39XTeWklPQ44","executionInfo":{"status":"ok","timestamp":1715105275252,"user_tz":-330,"elapsed":379,"user":{"displayName":"Aakanksha Patil","userId":"12153990072553635480"}},"outputId":"aea80bfd-8e34-44e3-92e9-b8084321eab0"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["['Hey', 'there', '!', '😀', 'Just', 'wanted', 'to', 'say', 'hi', '!', '🙌', 'Hope', \"you're\", 'doing', 'well', '.', '🌞', \"Let's\", 'catch', 'up', 'soon', '!', '🍕', '🥤']\n"]}]},{"cell_type":"code","source":["tokenizer = MWETokenizer()\n","tokenizer.add_mwe(('catch' , 'up'))\n","print(tokenizer.tokenize(word_tokenize(text)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6mc5SbqpPZgB","executionInfo":{"status":"ok","timestamp":1715105325605,"user_tz":-330,"elapsed":4,"user":{"displayName":"Aakanksha Patil","userId":"12153990072553635480"}},"outputId":"a8d9e286-d507-4e60-8eb2-7382a1e9fe79"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["['Hey', 'there', '!', '😀', 'Just', 'wanted', 'to', 'say', 'hi', '!', '🙌', 'Hope', 'you', \"'re\", 'doing', 'well', '.', '🌞', 'Let', \"'s\", 'catch_up', 'soon', '!', '🍕🥤']\n"]}]},{"cell_type":"code","source":["from nltk.probability import FreqDist\n","fdist=FreqDist(text)\n","fdist.N()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EM2CpP5sPlzG","executionInfo":{"status":"ok","timestamp":1715105386018,"user_tz":-330,"elapsed":6,"user":{"displayName":"Aakanksha Patil","userId":"12153990072553635480"}},"outputId":"ff85d9e3-cbc5-44de-9a6f-5ce0c47fcc56"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["87"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk import pos_tag\n","\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","\n","def pos_tagging(text):\n","\n","    words = word_tokenize(text)\n","\n","    pos_tags = pos_tag(words)\n","\n","    return pos_tags\n","\n","\n","\n","result = pos_tagging(text)\n","print(result)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bw4lxpnIPva0","executionInfo":{"status":"ok","timestamp":1715105532887,"user_tz":-330,"elapsed":367,"user":{"displayName":"Aakanksha Patil","userId":"12153990072553635480"}},"outputId":"9fd92e3e-6eef-4f2f-906f-592a03951e12"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["[('Hey', 'NNP'), ('there', 'EX'), ('!', '.'), ('😀', 'NN'), ('Just', 'RB'), ('wanted', 'VBD'), ('to', 'TO'), ('say', 'VB'), ('hi', 'NN'), ('!', '.'), ('🙌', 'CC'), ('Hope', 'NNP'), ('you', 'PRP'), (\"'re\", 'VBP'), ('doing', 'VBG'), ('well', 'RB'), ('.', '.'), ('🌞', 'VB'), ('Let', 'NNP'), (\"'s\", 'POS'), ('catch', 'VB'), ('up', 'RP'), ('soon', 'RB'), ('!', '.'), ('🍕🥤', 'NN')]\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]}]},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","\n","def remove_stopwords(text):\n","\n","    words = word_tokenize(text)\n","\n","    stop_words = set(stopwords.words('english'))\n","\n","    filtered_words = [word for word in words if word.lower() not in stop_words]\n","\n","    filtered_text = ' '.join(filtered_words)\n","\n","    return filtered_text\n","\n","\n","result = remove_stopwords(text)\n","print(result)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucBBaTsiQYaM","executionInfo":{"status":"ok","timestamp":1715106043530,"user_tz":-330,"elapsed":9,"user":{"displayName":"Aakanksha Patil","userId":"12153990072553635480"}},"outputId":"6b748e72-54bd-4893-aa90-d300fa6bdf29"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Hey ! 😀 wanted say hi ! 🙌 Hope 're well . 🌞 Let 's catch soon ! 🍕🥤\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["import nltk\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","\n","stemmer = PorterStemmer()\n","\n","sentence = \"The dogs are running in the park\"\n","\n","words = word_tokenize(sentence)\n","\n","stemmed_words = [stemmer.stem(word) for word in words]\n","\n","print(stemmed_words)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tRS6pdoTQtgY","executionInfo":{"status":"ok","timestamp":1715106094197,"user_tz":-330,"elapsed":18,"user":{"displayName":"Aakanksha Patil","userId":"12153990072553635480"}},"outputId":"8cf1231f-6d13-4bfd-b01d-887aab1d0383"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["['the', 'dog', 'are', 'run', 'in', 'the', 'park']\n"]}]},{"cell_type":"code","source":["\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize\n","\n","\n","lemmatizer = WordNetLemmatizer()\n","\n","sentence = \"The dogs are running in the park\"\n","\n","words = word_tokenize(sentence)\n","\n","lemmatized_words = [lemmatizer.lemmatize(word, pos='v') for word in words]\n","\n","print(lemmatized_words)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UA9BEJLZRKE7","executionInfo":{"status":"ok","timestamp":1715106094698,"user_tz":-330,"elapsed":19,"user":{"displayName":"Aakanksha Patil","userId":"12153990072553635480"}},"outputId":"416bf6b8-1236-4a7c-e772-c7b1b223f147"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["['The', 'dog', 'be', 'run', 'in', 'the', 'park']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"bP8HGVEiRtN3"},"execution_count":null,"outputs":[]}]}